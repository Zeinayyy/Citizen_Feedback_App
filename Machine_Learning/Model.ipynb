{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "4VDNoe_dk_qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_8iJlc9medw",
        "outputId": "24163920-26b6-4cb5-e50d-a0d5e0cae8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Perform one-hot encoding on labels\n",
        "        label_encoder = OneHotEncoder(sparse=False)\n",
        "        self.labels = label_encoder.fit_transform(labels.values.reshape(-1, 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.texts[index])\n",
        "        label = self.labels[index]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(label, dtype=torch.float32)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "j1Sjs3AzbkwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df  = pd.read_csv(\"/content/drive/MyDrive/data_polarity (1).csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "smoa8tWilBsH",
        "outputId": "e8b25f63-7bd9-4389-e16c-5cc99ada2d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          created_at                   id reply_count  \\\n",
              "0     Mon May 15 11:22:33 +0000 2023  1658070357826490112           0   \n",
              "1     Mon May 15 11:43:48 +0000 2023  1658075703882170112           0   \n",
              "2     Mon May 15 11:07:11 +0000 2023  1658066490258769920           0   \n",
              "3     Mon May 15 11:00:55 +0000 2023  1658064915532480000           0   \n",
              "4     Mon May 15 11:15:36 +0000 2023  1658068608453410048           0   \n",
              "...                              ...                  ...         ...   \n",
              "3617  Sun Nov 27 23:37:59 +0000 2022  1597011888050959872           0   \n",
              "3618  Mon Nov 28 00:59:41 +0000 2022  1597032446046109952           0   \n",
              "3619  Sun Nov 27 06:16:00 +0000 2022  1596749661821280000         131   \n",
              "3620  Sun Nov 27 10:52:33 +0000 2022  1596819259673299968           1   \n",
              "3621  Mon Nov 28 03:23:42 +0000 2022  1597068690335620096           0   \n",
              "\n",
              "     retweet_count favorite_count         username  \\\n",
              "0                0              1       jalan_yuuk   \n",
              "1                0              0         zeronol0   \n",
              "2                0              0       PA_5060_AS   \n",
              "3                0              1     bagrenresppu   \n",
              "4                0              0     raksulonline   \n",
              "...            ...            ...              ...   \n",
              "3617             0              1       AgoiTaufik   \n",
              "3618             0              0      RagaSukma_1   \n",
              "3619           255           1012         txtdrjkt   \n",
              "3620             0              2  SupratmanAndang   \n",
              "3621             0              0      BKoentjahya   \n",
              "\n",
              "                                             clean_text  \\\n",
              "0     saat kota yang lain sibuk berlomba agar wisata...   \n",
              "1     tankid laksono lol tolol  lu pikir keren gitu ...   \n",
              "2     di merauke minyak tanah susah selain jalan jug...   \n",
              "3     polres ppu polda kaltim  wujud kepedulian pols...   \n",
              "4     traffic light rusak jalan borong rayabatua ray...   \n",
              "...                                                 ...   \n",
              "3617  hahahahahebat itulah kalau cebong punya hajata...   \n",
              "3618  yah  tweet  polri tni    cari pesertanya itu d...   \n",
              "3619                               yaelah wargaðÿ˜¢ðÿ˜¢   \n",
              "3620  ternyata cuma menyisakan sampah dimanamana tuk...   \n",
              "3621  cega kasihan masyarakat dibodohi dibayar dikas...   \n",
              "\n",
              "                                      preprocessed_text  polarity_score  \\\n",
              "0     ['kota', 'sibuk', 'berlomba', 'wisatawan', 'ko...              -1   \n",
              "1     ['tankid', 'laksono', 'lol', 'tolol', 'lu', 'p...             -26   \n",
              "2     ['merauke', 'minyak', 'tanah', 'susah', 'jalan...             -14   \n",
              "3     ['polres', 'ppu', 'polda', 'kaltim', 'wujud', ...               4   \n",
              "4     ['traffic', 'light', 'rusak', 'jalan', 'borong...              -5   \n",
              "...                                                 ...             ...   \n",
              "3617  ['hahahahahebat', 'cebong', 'hajatan', 'ngepra...              -6   \n",
              "3618  ['yah', 'tweet', 'polri', 'tni', 'cari', 'pese...             -21   \n",
              "3619                        ['yaelah', 'wargaðÿ˜¢ðÿ˜¢']               0   \n",
              "3620  ['menyisakan', 'sampah', 'dimanamana', 'tuk', ...               2   \n",
              "3621  ['cega', 'kasihan', 'masyarakat', 'dibodohi', ...               2   \n",
              "\n",
              "      polarity  \n",
              "0     negative  \n",
              "1       urgent  \n",
              "2       urgent  \n",
              "3     positive  \n",
              "4     negative  \n",
              "...        ...  \n",
              "3617  negative  \n",
              "3618    urgent  \n",
              "3619   neutral  \n",
              "3620  positive  \n",
              "3621  positive  \n",
              "\n",
              "[3622 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d217a98-3f50-4b38-b300-495ccd12239f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>username</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>polarity_score</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mon May 15 11:22:33 +0000 2023</td>\n",
              "      <td>1658070357826490112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>jalan_yuuk</td>\n",
              "      <td>saat kota yang lain sibuk berlomba agar wisata...</td>\n",
              "      <td>['kota', 'sibuk', 'berlomba', 'wisatawan', 'ko...</td>\n",
              "      <td>-1</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mon May 15 11:43:48 +0000 2023</td>\n",
              "      <td>1658075703882170112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>zeronol0</td>\n",
              "      <td>tankid laksono lol tolol  lu pikir keren gitu ...</td>\n",
              "      <td>['tankid', 'laksono', 'lol', 'tolol', 'lu', 'p...</td>\n",
              "      <td>-26</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mon May 15 11:07:11 +0000 2023</td>\n",
              "      <td>1658066490258769920</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>PA_5060_AS</td>\n",
              "      <td>di merauke minyak tanah susah selain jalan jug...</td>\n",
              "      <td>['merauke', 'minyak', 'tanah', 'susah', 'jalan...</td>\n",
              "      <td>-14</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mon May 15 11:00:55 +0000 2023</td>\n",
              "      <td>1658064915532480000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>bagrenresppu</td>\n",
              "      <td>polres ppu polda kaltim  wujud kepedulian pols...</td>\n",
              "      <td>['polres', 'ppu', 'polda', 'kaltim', 'wujud', ...</td>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mon May 15 11:15:36 +0000 2023</td>\n",
              "      <td>1658068608453410048</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>raksulonline</td>\n",
              "      <td>traffic light rusak jalan borong rayabatua ray...</td>\n",
              "      <td>['traffic', 'light', 'rusak', 'jalan', 'borong...</td>\n",
              "      <td>-5</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3617</th>\n",
              "      <td>Sun Nov 27 23:37:59 +0000 2022</td>\n",
              "      <td>1597011888050959872</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>AgoiTaufik</td>\n",
              "      <td>hahahahahebat itulah kalau cebong punya hajata...</td>\n",
              "      <td>['hahahahahebat', 'cebong', 'hajatan', 'ngepra...</td>\n",
              "      <td>-6</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3618</th>\n",
              "      <td>Mon Nov 28 00:59:41 +0000 2022</td>\n",
              "      <td>1597032446046109952</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RagaSukma_1</td>\n",
              "      <td>yah  tweet  polri tni    cari pesertanya itu d...</td>\n",
              "      <td>['yah', 'tweet', 'polri', 'tni', 'cari', 'pese...</td>\n",
              "      <td>-21</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3619</th>\n",
              "      <td>Sun Nov 27 06:16:00 +0000 2022</td>\n",
              "      <td>1596749661821280000</td>\n",
              "      <td>131</td>\n",
              "      <td>255</td>\n",
              "      <td>1012</td>\n",
              "      <td>txtdrjkt</td>\n",
              "      <td>yaelah wargaðÿ˜¢ðÿ˜¢</td>\n",
              "      <td>['yaelah', 'wargaðÿ˜¢ðÿ˜¢']</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3620</th>\n",
              "      <td>Sun Nov 27 10:52:33 +0000 2022</td>\n",
              "      <td>1596819259673299968</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>SupratmanAndang</td>\n",
              "      <td>ternyata cuma menyisakan sampah dimanamana tuk...</td>\n",
              "      <td>['menyisakan', 'sampah', 'dimanamana', 'tuk', ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3621</th>\n",
              "      <td>Mon Nov 28 03:23:42 +0000 2022</td>\n",
              "      <td>1597068690335620096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BKoentjahya</td>\n",
              "      <td>cega kasihan masyarakat dibodohi dibayar dikas...</td>\n",
              "      <td>['cega', 'kasihan', 'masyarakat', 'dibodohi', ...</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3622 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d217a98-3f50-4b38-b300-495ccd12239f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d217a98-3f50-4b38-b300-495ccd12239f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d217a98-3f50-4b38-b300-495ccd12239f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = df['preprocessed_text']\n",
        "train_labels = df['polarity']"
      ],
      "metadata": {
        "id": "_muxsc1RnAQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
        "max_length = 512\n",
        "train_dataset = SentimentDataset(train_text, train_labels, tokenizer, max_length)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcJ-wa3NoMKm",
        "outputId": "12369177-0033-48e0-af87-d63d67ebf859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8WSXxMzZzRu",
        "outputId": "470fb646-88b8-493f-e100-405d445688ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"indobenchmark/indobert-base-p1\", num_labels=2)\n",
        "model.to(device)\n",
        "model.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
        "model.classifier.bias.data.zero_()\n",
        "\n",
        "# Define your dataset and dataloader\n",
        "# Make sure your dataset is formatted as tokenized input sequences with corresponding labels\n",
        "\n",
        "# Example dataset and dataloader\n",
        "train_dataset = train_dataset\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Set the number of training epochs and learning rate\n",
        "num_epochs = 5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# Define the optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {average_loss:.4f}\")\n"
      ]
    }
  ]
}